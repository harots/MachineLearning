{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "if IS_COLAB or IS_KAGGLE:\n",
        "    !echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "    !curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "    !apt update && apt-get install -y tensorflow-model-server\n",
        "    %pip install -q -U tensorflow-serving-api\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "    if IS_KAGGLE:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deploy\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urcBTpyarR6M",
        "outputId": "cb37c888-dfd4-4a78-b6ad-6282e390355e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "100  2943  100  2943    0     0   5877      0 --:--:-- --:--:-- --:--:--  5886\n",
            "OK\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "40 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mhttp://storage.googleapis.com/tensorflow-serving-apt/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tensorflow-model-server is already the newest version (2.19.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "No GPU was detected. CNNs can be very slow without a GPU.\n",
            "Go to Runtime > Change runtime and select a GPU hardware accelerator.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_test = X_test[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_new = X_test[:3]"
      ],
      "metadata": {
        "id": "XcolZyCesHhd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MV8DMQGsOgP",
        "outputId": "e895052d-f53f-4867-c4b9-d442063c8cc5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.7071 - loss: 1.0970 - val_accuracy: 0.9006 - val_loss: 0.3746\n",
            "Epoch 2/10\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8956 - loss: 0.3743 - val_accuracy: 0.9174 - val_loss: 0.3004\n",
            "Epoch 3/10\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.3121 - val_accuracy: 0.9260 - val_loss: 0.2655\n",
            "Epoch 4/10\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2778 - val_accuracy: 0.9336 - val_loss: 0.2417\n",
            "Epoch 5/10\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.2529 - val_accuracy: 0.9382 - val_loss: 0.2230\n",
            "Epoch 6/10\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9350 - loss: 0.2328 - val_accuracy: 0.9438 - val_loss: 0.2077\n",
            "Epoch 7/10\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9391 - loss: 0.2158 - val_accuracy: 0.9484 - val_loss: 0.1947\n",
            "Epoch 8/10\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.2012 - val_accuracy: 0.9512 - val_loss: 0.1835\n",
            "Epoch 9/10\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1885 - val_accuracy: 0.9536 - val_loss: 0.1740\n",
            "Epoch 10/10\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1774 - val_accuracy: 0.9564 - val_loss: 0.1657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78d34f277b10>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(model.predict(X_new), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glBNdlL4sPNK",
        "outputId": "00b35696-3980-45ae-eb0f-13363dfbe902"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_version = \"0001\"\n",
        "model_name = \"my_mnist_model\"\n",
        "model_path = os.path.join(model_name, model_version)\n",
        "model_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xIY3sU6XsUVb",
        "outputId": "64bf4b3f-75ec-4fe1-9f69-d9d9bd995836"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'my_mnist_model/0001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, model_path)"
      ],
      "metadata": {
        "id": "BPKcM3kFsZX-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for root, dirs, files in os.walk(model_name):\n",
        "    indent = '    ' * root.count(os.sep)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    for filename in files:\n",
        "        print('{}{}'.format(indent + '    ', filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2ktQqT6sdyb",
        "outputId": "cac43cf8-dd7f-4784-cb92-a140444d0d37"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_mnist_model/\n",
            "    0001/\n",
            "        fingerprint.pb\n",
            "        saved_model.pb\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n",
            "        assets/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!saved_model_cli show --dir {model_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbUbNFpxwBtf",
        "outputId": "4a778709-3de8-4604-abc1-9c2240033022"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-20 14:31:37.486600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750429897.570757    7958 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750429897.583383    7958 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1750429897.665831    7958 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429897.665967    7958 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429897.665978    7958 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429897.665987    7958 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-20 14:31:46.646761: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "The given SavedModel contains the following tag-sets:\n",
            "'serve'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!saved_model_cli show --dir {model_path} --tag_set serve"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whzwqJ2vwEUP",
        "outputId": "67ff1943-e5db-4c32-b2c1-2ab134f3ce37"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-20 14:31:48.860247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750429908.881952    8018 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750429908.888553    8018 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1750429908.904754    8018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429908.904800    8018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429908.904805    8018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429908.904808    8018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-20 14:31:55.446834: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
            "SignatureDef key: \"__saved_model_init_op\"\n",
            "SignatureDef key: \"serving_default\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!saved_model_cli show --dir {model_path} --tag_set serve \\\n",
        "                      --signature_def serving_default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO7k7GcewE1k",
        "outputId": "3aefa270-e279-4213-e1ea-ac7610194f8b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-20 14:31:57.311216: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750429917.349892    8058 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750429917.360487    8058 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1750429917.386032    8058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429917.386093    8058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429917.386099    8058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429917.386103    8058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-20 14:32:03.274143: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['inputs'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 28, 28, 1)\n",
            "      name: serving_default_inputs:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['output_0'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!saved_model_cli show --dir {model_path} --all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqBU5FsLwG7m",
        "outputId": "528e14fc-3767-4b9d-f406-00530259bdbd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-20 14:32:05.958290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750429925.996336    8098 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750429926.007643    8098 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1750429926.031555    8098 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429926.031609    8098 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429926.031617    8098 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429926.031624    8098 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-20 14:32:12.516355: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['inputs'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_inputs:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['output_0'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "The MetaGraph with tag set ['serve'] contains the following ops: {'Relu', 'Reshape', 'RestoreV2', 'DisableCopyOnRead', 'VarHandleOp', 'MatMul', 'Identity', 'ShardedFilename', 'NoOp', 'AssignVariableOp', 'StaticRegexFullMatch', 'SaveV2', 'MergeV2Checkpoints', 'ReadVariableOp', 'Select', 'Pack', 'StatefulPartitionedCall', 'StringJoin', 'Const', 'Placeholder', 'VarIsInitializedOp', 'BiasAdd', 'Softmax'}\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"my_mnist_tests.npy\", X_new)"
      ],
      "metadata": {
        "id": "4GH1aYT0wIOl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_name = model.layers[0].name\n",
        "input_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aGt2svQAwJHe",
        "outputId": "7091adec-ffe9-4bc4-9269-903d1cbefd46"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'flatten_1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!saved_model_cli run --dir {model_path} --tag_set serve \\\n",
        "                     --signature_def serving_default    \\\n",
        "                     --inputs {input_name}=my_mnist_tests.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LgDIiVuwKz-",
        "outputId": "01bfaa73-dd7d-4cf7-bc4b-34eb1b3d4b6a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-20 14:32:14.555854: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750429934.578216    8147 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750429934.585462    8147 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1750429934.602575    8147 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429934.602636    8147 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429934.602641    8147 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1750429934.602645    8147 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-20 14:32:21.824511: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/saved_model_cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/tools/saved_model_cli.py\", line 1340, in main\n",
            "    app.run(smcli_main)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/tools/saved_model_cli.py\", line 1338, in smcli_main\n",
            "    args.func()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/tools/saved_model_cli.py\", line 1036, in run\n",
            "    run_saved_model_with_feed_dict(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/tools/saved_model_cli.py\", line 685, in run_saved_model_with_feed_dict\n",
            "    raise ValueError(\n",
            "ValueError: \"flatten_1\" is not a valid input key. Please choose from \"inputs\", or use --show option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round([[1.1347984e-04, 1.5187356e-07, 9.7032893e-04, 2.7640699e-03, 3.7826971e-06,\n",
        "           7.6876910e-05, 3.9140293e-08, 9.9559116e-01, 5.3502394e-05, 4.2665208e-04],\n",
        "          [8.2443521e-04, 3.5493889e-05, 9.8826385e-01, 7.0466995e-03, 1.2957400e-07,\n",
        "           2.3389691e-04, 2.5639210e-03, 9.5886099e-10, 1.0314899e-03, 8.7952529e-08],\n",
        "          [4.4693781e-05, 9.7028232e-01, 9.0526715e-03, 2.2641101e-03, 4.8766597e-04,\n",
        "           2.8800720e-03, 2.2714981e-03, 8.3753867e-03, 4.0439744e-03, 2.9759688e-04]], 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB5h12Y6wNEe",
        "outputId": "13022bfb-a841-4db1-d1a0-7cbee6031b7f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MODEL_DIR\"] = os.path.split(os.path.abspath(model_path))[0]"
      ],
      "metadata": {
        "id": "urhkA4EywO84"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg\n",
        "nohup tensorflow_model_server \\\n",
        "     --rest_api_port=8601 \\\n",
        "     --rest_api_host=0.0.0.0 \\\n",
        "     --model_name=my_mnist_model \\\n",
        "     --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "metadata": {
        "id": "_RW6Udm0wPyY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail server.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCqMY9efwQ31",
        "outputId": "aa6888e2-6a11-473a-e778-583113f4a4ab"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t--num_tflite_interpreters_per_pool=1\tint32\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Number of TFLite interpreters in an interpreter pool of TfLiteSession. Typically there is one TfLiteSession for each TF Lite model that is loaded. If not set, will be 1.\n",
            "\t--enable_signature_method_name_check=false\tbool\tEnable method_name check for SignatureDef. Disable this if serving native TF2 regression/classification models.\n",
            "\t--xla_cpu_compilation_enabled=false\tbool\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Enable XLA:CPU JIT (default is disabled). With XLA:CPU JIT disabled, models utilizing this feature will return bad Status on first compilation request.\n",
            "\t--xla_gpu_compilation_enabled=false\tbool\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Enable both XLA:CPU JIT anWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1750429953.425457    8243 loader_harness.cc:71] Approving load for servable version {name: my_mnist_model version: 1}\n",
            "I0000 00:00:1750429953.425621    8243 loader_harness.cc:79] Loading servable version {name: my_mnist_model version: 1}\n",
            "I0000 00:00:1750429953.508848    8243 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
            "I0000 00:00:1750429953.918844    8243 loader_harness.cc:105] Successfully loaded servable version {name: my_mnist_model version: 1}\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "[evhttp_server.cc : 261] NET_LOG: Entering the event loop ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "input_data_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist(),\n",
        "})"
      ],
      "metadata": {
        "id": "nIUOjv4UwR6g"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repr(input_data_json)[:1500] + \"...\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "PLZYLgU6wTR0",
        "outputId": "fdb4ebfe-05dd-45f9-ae29-57a828f1cf87"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\'{\"signature_name\": \"serving_default\", \"instances\": [[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.32941177487373...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercises**\n",
        "1. What does a SavedModel contain? How do you inspect its content?\n",
        "2. When should you use TF Serving? What are its main features? What are some\n",
        "tools you can use to deploy it?\n",
        "3. How do you deploy a model across multiple TF Serving instances?\n",
        "4. When should you use the gRPC API rather than the REST API to query a model\n",
        "served by TF Serving?\n",
        "5. What are the different ways TFLite reduces a model’s size to make it run on a\n",
        "mobile or embedded device?\n",
        "6. What is quantization-aware training, and why would you need it?\n",
        "7. What are model parallelism and data parallelism? Why is the latter generally\n",
        "recommended?\n",
        "8. When training a model across multiple servers, what distribution strategies can\n",
        "you use? How do you choose which one to use?\n",
        "9. Train a model (any model you like) and deploy it to TF Serving or Google Cloud\n",
        "AI Platform. Write the client code to query it using the REST API or the gRPC API. Update the model and deploy the new version. Your client code will now\n",
        "query the new version. Roll back to the first version.\n",
        "10. Train any model across multiple GPUs on the same machine using the Mirrored\n",
        "Strategy (if you do not have access to GPUs, you can use Colaboratory with a\n",
        "GPU Runtime and create two virtual GPUs). Train the model again using the\n",
        "CentralStorageStrategy and compare the training time.\n",
        "11. Train a small model on Google Cloud AI Platform, using black box hyperpara‐\n",
        "meter tuning."
      ],
      "metadata": {
        "id": "kOVoWOoKxbiq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Jawaban**\n",
        "1. SavedModel adalah format penyimpanan model TensorFlow yang berisi arsitektur (graf komputasi) dan bobot model. Disimpan dalam folder yang berisi file saved_model.pb (graf komputasi) dan folder variables (nilai variabel/bobot). Jika bobotnya banyak, bisa terpecah dalam beberapa file. Ada juga folder assets untuk data tambahan (seperti vocab atau contoh data). SavedModel bisa memuat satu atau lebih metagraph (graf + definisi input/output). SavedModel bisa dilihat pakai saved_model_cli atau di-load dengan tf.saved_model.load().\n",
        "\n",
        "2. TF Serving memudahkan kita untuk deploy banyak model TensorFlow (atau versi berbeda dari satu model) lewat REST API atau gRPC API. Jadi, nggak perlu repot update model di tiap aplikasi. TF Serving bisa otomatis memantau folder, memuat model baru tanpa restart aplikasi, performa cepat, mendukung A/B testing, canary release, dan batching request ke GPU. Instalasi paling mudah pakai Docker, bisa di-orchestrate dengan Kubernetes atau pakai layanan cloud seperti Google Cloud AI Platform.\\\n",
        "\n",
        "3. Untuk deploy model ke banyak instance TF Serving, cukup atur semua instance agar memantau folder model yang sama, lalu ekspor model baru sebagai SavedModel ke subfolder di dalamnya.\n",
        "\n",
        "4. gRPC API lebih efisien dari REST API, tapi library-nya tidak seluas REST. Jika REST API pakai kompresi, performanya hampir setara. Jadi, gRPC cocok dipakai jika butuh performa maksimal dan kliennya bisa pakai gRPC\n",
        "\n",
        "5. TFLite mengecilkan ukuran model agar bisa jalan di perangkat mobile/embedded dengan:\n",
        "\n",
        "* Menggunakan converter untuk optimasi SavedModel (memangkas operasi tak perlu, menggabungkan operasi).\n",
        "\n",
        "* Melakukan post-training quantization agar ukuran model jauh lebih kecil dan cepat diunduh.\n",
        "\n",
        "* Menyimpan model dalam format FlatBuffer yang langsung bisa dimuat ke RAM, sehingga loading lebih cepat dan hemat memori\n",
        "\n",
        "6. Quantization-aware training menambahkan operasi kuantisasi palsu saat training, supaya model belajar mengabaikan noise kuantisasi. Hasilnya, bobot model jadi lebih tahan terhadap kuantisasi.\n",
        "\n",
        "7. Model parallelism membagi model ke beberapa bagian dan menjalankannya di banyak perangkat secara paralel.\n",
        "Data parallelism menggandakan model jadi beberapa replika di berbagai perangkat, lalu tiap replika melatih batch data berbeda.\n",
        "\n",
        "* Pada synchronous data parallelism, semua gradien digabung lalu di-update bersama.\n",
        "\n",
        "* Pada asynchronous data parallelism, tiap replika update parameter pusat secara mandiri tanpa menunggu lainnya.\n",
        "\n",
        "8. Saat melatih model di banyak server, ada dua strategi distribusi utama:\n",
        "\n",
        "* MultiWorkerMirroredStrategy: pakai data parallelism sinkron. Model direplikasi di semua server & device, tiap replika dapat batch data berbeda. Gradien dihitung, dirata-ratakan (AllReduce), lalu semua replika update bareng. Ini paling simpel & umumnya disarankan. Syaratnya: model harus muat di RAM tiap replika.\n",
        "\n",
        "* ParameterServerStrategy: pakai data parallelism asinkron. Model direplikasi di worker, parameter dibagi di server parameter. Tiap worker jalan mandiri, ambil param terbaru, hitung gradien, kirim ke server. Server update parameter. Biasanya lebih lambat dari strategi pertama."
      ],
      "metadata": {
        "id": "Ed-eOXazxlI1"
      }
    }
  ]
}